

experim_name: 'default'
################################################################################
# training parameters
################################################################################
pretrained_root: 'checkpoints'
n_gpu: 1
root: '/home/tiago/Dropbox/research/datasets'
root_ws: "C:\\Users\\Tiago\\TB\\datasets"

retrieval:
  top_cand: [1,5]
  range_thres: 6

train_loader:
  data:
    dataset: 'orchard-uk'
    sequence: 'rerecord_sparce'
    aug: False
    modality: 'range'

  fraction: 0.3 
  batch_size: 1       # batch size
  shuffle: False
  #rotation: [180,-45,-45]
  
val_loader:
  data:
    dataset: 'orchard-uk'
    sequence: 'rerecord_sparce'
    modality: 'range' # ['range',projection,bev]'intensity','density','height','bev']
  batch_size: 1 #50         # batch size
  workers:  0            # number of threads to get data
  shuffle: False
  #rotation: [180,-45,-45]

model:
  type: 'AttVLAD_resnet50'
  minibatch_size: 50
  pretrained_backbone: True
  output_dim: 256
  #in_channels: 1

bev_param:
  in_channels: 3
  max_samples: 256
  cluster_size: 20

height_param:
  in_channels: 1
  max_samples: 128
  cluster_size: 20

rp_param:
  in_channels: 5
  max_samples: 64
  cluster_size: 20

range_param:
  in_channels: 1
  max_samples: 64
  cluster_size: 20

pcl_param:
  in_channels: 1
  max_samples: 128
  cluster_size: 64

loss:
  type: 'TripletLoss'
  args:
    margin: 0.5
    metric: 'kl_divergence' # [L2,Hinge,cosine,kl_divergence]
    reduction: 'mean'


trainer:
  iter_per_epoch: 1
  epochs: 1000
  report_val: 3        # every x epochs, report validation set
  save_period: 3
  log_dir: "saved/"
  save_dir: "checkpoints/"
  monitor: "max recall" # [off, max mIoU]
  val_per_epochs: 3
  results_dir: "/media/tiago/BIG/Orchards/temp/"


optimizer:
  type: "AdamW" #[RMSprop,Adam,SGD]
  args:
    lr: 0.001
    weight_decay: 0.05
  lr_scheduler: "ReduceLROnPlateau"

StepLR:
  step_size: 20 
  gamma: 0.1

CosineAnnealingWarmRestarts:
  T_0: 5
  T_mult: 2
  eta_min: 0.00001 # Min learning rate


ReduceLROnPlateau:
  mode: 'min' #['min','max'] (str)
  factor: 0.01
  patience: 5 # Number of epochs with no improvement after which learning rate will be reduced. 
  min_lr: 0.000001

